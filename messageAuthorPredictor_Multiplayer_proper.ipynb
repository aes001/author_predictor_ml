{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some notes on how to set up GPU for tensorflow in Jupyter notebook\n",
    "#%env PATH=\"/home/aes/Datamining/.venv/bin:/usr/local/lib/nodejs/node-v20.11.0-linux-x64/bin:/home/aes/.local/bin:/usr/local/cuda-12.4/bin:/usr/java/jdk-21.0.2/bin:/opt/gradle/gradle-8.5/bin:/usr/local/go/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/lib/wsl/lib:/mnt/c/Program Files/NVIDIA/CUDNN/v9.1/bin:/mnt/c/Python311/Scripts/:/mnt/c/Python311/:/mnt/c/Windows/system32:/mnt/c/Windows:/mnt/c/Windows/System32/Wbem:/mnt/c/Windows/System32/WindowsPowerShell/v1.0/:/mnt/c/Windows/System32/OpenSSH/:/mnt/c/Program Files (x86)/NVIDIA Corporation/PhysX/Common:/mnt/c/Program Files/Calibre2/:/mnt/c/Program Files/dotnet/:/mnt/c/Program Files/Git/cmd:/mnt/c/Program Files/nodejs/:/mnt/c/ProgramData/chocolatey/bin:/mnt/c/Program Files/MySQL/MySQL Server 8.0/bin:/mnt/c/Program Files/MySQL/MySQL Router 8.0/bin:/mnt/c/Program Files/MySQL/MySQL Shell 8.0/bin:/mnt/c/Program Files/yt-dlp:/mnt/c/Program Files (x86)/GnuPG/bin:/mnt/c/Program Files/Mullvad VPN/resources:/mnt/c/Program Files (x86)/Pulse Secure/VC142.CRT/X64/:/mnt/c/Program Files (x86)/Pulse Secure/VC142.CRT/X86/:/mnt/c/Program Files/Docker/Docker/resources/bin:/mnt/c/Strawberry/c/bin:/mnt/c/Strawberry/perl/site/bin:/mnt/c/Strawberry/perl/bin:/mnt/c/Program Files/NVIDIA Corporation/NVIDIA NvDLISR:/mnt/c/Users/aesun/AppData/Local/Programs/Python/Python312/Scripts/:/mnt/c/Users/aesun/AppData/Local/Programs/Python/Python312/:/mnt/c/Users/aesun/AppData/Local/Microsoft/WindowsApps:/mnt/c/Users/aesun/AppData/Local/Programs/Microsoft VS Code/bin:/mnt/c/Users/aesun/AppData/Roaming/npm:/mnt/c/Users/aesun/AppData/Local/Programs/MiKTeX/miktex/bin/x64/:/mnt/c/Program Files/Neovim/bin:/snap/bin:/usr/local/cuda-12.4/bin\"\n",
    "#%env LD_LIBRARY_PATH=\"/home/aes/Datamining/.venv/lib/python3.10/site-packages/nvidia/cudnn/lib:/usr/local/cuda-12.4/lib64:/usr/local/cuda-12.4/extras/CUPTI/lib64:/usr/local/cuda-12.4/lib64\"\n",
    "#%env CUDNN_PATH=\"/home/aes/Datamining/.venv/lib/python3.10/site-packages/nvidia/cudnn\"\n",
    "\n",
    "# You should set up cudnn path in your system to get GPU to work\n",
    "# export CUDNN_PATH=\"/home/aes/Datamining/.venv/lib/python3.10/site-packages/nvidia/cudnn\"\n",
    "# and\n",
    "# export LD_LIBRARY_PATH=\"$CUDNN_PATH/lib\":\"/usr/local/cuda-12.4/lib64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin:/home/aes/.local/bin:/home/aes/.vscode-server/bin/e170252f762678dec6ca2cc69aba1570769a5d39/bin/remote-cli:/usr/local/lib/nodejs/node-v20.11.0-linux-x64/bin:/home/aes/.local/bin:/usr/local/cuda-12.4/bin:/usr/java/jdk-21.0.2/bin:/opt/gradle/gradle-8.5/bin:/usr/local/go/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/lib/wsl/lib:/mnt/c/Program Files/WindowsApps/MicrosoftCorporationII.WindowsSubsystemForLinux_2.0.14.0_x64__8wekyb3d8bbwe:/mnt/c/Program Files/NVIDIA/CUDNN/v9.1/bin:/mnt/c/Python311/Scripts/:/mnt/c/Python311/:/mnt/c/Windows/system32:/mnt/c/Windows:/mnt/c/Windows/System32/Wbem:/mnt/c/Windows/System32/WindowsPowerShell/v1.0/:/mnt/c/Windows/System32/OpenSSH/:/mnt/c/Program Files (x86)/NVIDIA Corporation/PhysX/Common:/mnt/c/Program Files/Calibre2/:/mnt/c/Program Files/dotnet/:/mnt/c/Program Files/Git/cmd:/mnt/c/Program Files/nodejs/:/mnt/c/ProgramData/chocolatey/bin:/mnt/c/Program Files/MySQL/MySQL Server 8.0/bin:/mnt/c/Program Files/MySQL/MySQL Router 8.0/bin:/mnt/c/Program Files/MySQL/MySQL Shell 8.0/bin:/mnt/c/Program Files/yt-dlp:/mnt/c/Program Files (x86)/GnuPG/bin:/mnt/c/Program Files/Mullvad VPN/resources:/mnt/c/Program Files (x86)/Pulse Secure/VC142.CRT/X64/:/mnt/c/Program Files (x86)/Pulse Secure/VC142.CRT/X86/:/mnt/c/Program Files/Docker/Docker/resources/bin:/mnt/c/Strawberry/c/bin:/mnt/c/Strawberry/perl/site/bin:/mnt/c/Strawberry/perl/bin:/mnt/c/Program Files/NVIDIA Corporation/NVIDIA NvDLISR:/mnt/c/Users/aesun/AppData/Local/Programs/Python/Python312/Scripts/:/mnt/c/Users/aesun/AppData/Local/Programs/Python/Python312/:/mnt/c/Users/aesun/AppData/Local/Microsoft/WindowsApps:/mnt/c/Users/aesun/AppData/Local/Programs/Microsoft VS Code/bin:/mnt/c/Users/aesun/AppData/Roaming/npm:/mnt/c/Users/aesun/AppData/Local/Programs/MiKTeX/miktex/bin/x64/:/mnt/c/Program Files/Neovim/bin:/snap/bin:/home/aes/.vscode-server/bin/e170252f762678dec6ca2cc69aba1570769a5d39/bin/remote-cli:/usr/local/lib/nodejs/node-v20.11.0-linux-x64/bin:/home/aes/.local/bin:/usr/local/cuda-12.4/bin:/usr/java/jdk-21.0.2/bin:/opt/gradle/gradle-8.5/bin:/usr/local/go/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/lib/wsl/lib:/mnt/c/Program Files/WindowsApps/MicrosoftCorporationII.WindowsSubsystemForLinux_2.0.14.0_x64__8wekyb3d8bbwe:/mnt/c/Program Files/NVIDIA/CUDNN/v9.1/bin:/mnt/c/Python311/Scripts/:/mnt/c/Python311/:/mnt/c/Windows/system32:/mnt/c/Windows:/mnt/c/Windows/System32/Wbem:/mnt/c/Windows/System32/WindowsPowerShell/v1.0/:/mnt/c/Windows/System32/OpenSSH/:/mnt/c/Program Files (x86)/NVIDIA Corporation/PhysX/Common:/mnt/c/Program Files/Calibre2/:/mnt/c/Program Files/dotnet/:/mnt/c/Program Files/Git/cmd:/mnt/c/Program Files/nodejs/:/mnt/c/ProgramData/chocolatey/bin:/mnt/c/Program Files/MySQL/MySQL Server 8.0/bin:/mnt/c/Program Files/MySQL/MySQL Router 8.0/bin:/mnt/c/Program Files/MySQL/MySQL Shell 8.0/bin:/mnt/c/Program Files/yt-dlp:/mnt/c/Program Files (x86)/GnuPG/bin:/mnt/c/Program Files/Mullvad VPN/resources:/mnt/c/Program Files (x86)/Pulse Secure/VC142.CRT/X64/:/mnt/c/Program Files (x86)/Pulse Secure/VC142.CRT/X86/:/mnt/c/Program Files/Docker/Docker/resources/bin:/mnt/c/Strawberry/c/bin:/mnt/c/Strawberry/perl/site/bin:/mnt/c/Strawberry/perl/bin:/mnt/c/Program Files/NVIDIA Corporation/NVIDIA NvDLISR:/mnt/c/Users/aesun/AppData/Local/Programs/Python/Python312/Scripts/:/mnt/c/Users/aesun/AppData/Local/Programs/Python/Python312/:/mnt/c/Users/aesun/AppData/Local/Microsoft/WindowsApps:/mnt/c/Users/aesun/AppData/Local/Programs/Microsoft VS Code/bin:/mnt/c/Users/aesun/AppData/Roaming/npm:/mnt/c/Users/aesun/AppData/Local/Programs/MiKTeX/miktex/bin/x64/:/mnt/c/Program Files/Neovim/bin:/snap/bin\n",
      "/home/aes/Datamining/.venv/lib/python3.10/site-packages/nvidia/cudnn/lib:/usr/local/cuda-12.4/lib64\n",
      "/home/aes/Datamining/.venv/lib/python3.10/site-packages/nvidia/cudnn\n"
     ]
    }
   ],
   "source": [
    "!echo $PATH\n",
    "!echo $LD_LIBRARY_PATH\n",
    "!echo $CUDNN_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import urllib.request\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique authors: 5\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('uber_boat_cleaned.csv')\n",
    "data2 = pd.read_csv('ch_cleaned.csv')\n",
    "\n",
    "# Concatenate the two datasets\n",
    "data = pd.concat([data, data2])\n",
    "author = data['author']\n",
    "message = data['message']\n",
    "header = data.columns\n",
    "\n",
    "# Count the number of unique authors\n",
    "author_id = author.unique()\n",
    "print('Number of unique authors:', len(author_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# Set tensorflow debugging on or off\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "\n",
    "# Check if tensorflow is using the GPU\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# If you see num GPUs available as 0 then you should be worried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0.]\n",
      "Number of messages per author before oversampling: {0: 2789, 1: 2235, 2: 13275, 3: 1568, 4: 12259}\n",
      "Number of messages per author after oversampling: {0: 13275, 1: 13275, 2: 13275, 3: 13275, 4: 13275}\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the message\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(message)\n",
    "message_sequence = tokenizer.texts_to_sequences(message)\n",
    "\n",
    "# Pad the tokenized message sequence\n",
    "max_len = max([len(seq) for seq in message_sequence])\n",
    "message_sequence = tf.keras.utils.pad_sequences(message_sequence, maxlen=max_len)\n",
    "\n",
    "author_label = tf.keras.utils.to_categorical(author)\n",
    "print(author_label[0])\n",
    "\n",
    "# Count how many messages per author\n",
    "# First create a dictionary of authors and int\n",
    "author_id = author.unique() \n",
    "author_to_messages_count = {auth_id: 0 for auth_id in author_id}\n",
    "\n",
    "# Count the number of messages per author\n",
    "for a in author_label:\n",
    "    author_to_messages_count[np.argmax(a)] += 1\n",
    "\n",
    "print('Number of messages per author before oversampling:', author_to_messages_count)\n",
    "\n",
    "# Oversample the dataset\n",
    "smote = SMOTE()\n",
    "message_os, author_os = smote.fit_resample(message_sequence, author_label)\n",
    "\n",
    "# Count the number of messages per author after oversampling\n",
    "author_to_messages_count = {auth_id: 0 for auth_id in author_id}\n",
    "for a in author_os:\n",
    "    author_to_messages_count[np.argmax(a)] += 1\n",
    "\n",
    "print('Number of messages per author after oversampling:', author_to_messages_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training, validation and testing sets\n",
    "message_train, message_test, author_train, author_test = train_test_split(message_os, author_os, test_size=0.3, random_state=1, stratify=author_os)\n",
    "message_test, message_val, author_test, author_val = train_test_split(message_test, author_test, test_size=0.5, random_state=1, stratify=author_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(len(tokenizer.word_index)+1, 128, name='embedding'),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128), name='lstm'),\n",
    "    tf.keras.layers.Dense(128, activation='relu', name='dense'),\n",
    "    tf.keras.layers.Dropout(0.4, name='dropout'),\n",
    "    tf.keras.layers.Dense(64, activation='relu', name='dense2'),\n",
    "    tf.keras.layers.Dropout(0.4, name='dropout2'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax', name='output')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model stats before training\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.2168 - loss: 1.6097\n",
      "Test loss: 1.6094293594360352\n",
      "Test accuracy: 22.43%\n"
     ]
    }
   ],
   "source": [
    "print(\"Model stats before training\")\n",
    "test_pre_loss, test_pre_accuracy = model.evaluate(message_test, author_test)\n",
    "print('Test loss:', test_pre_loss)\n",
    "print(f\"Test accuracy: {test_pre_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "\u001b[1m1452/1452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 61ms/step - accuracy: 0.2446 - loss: 1.5812 - val_accuracy: 0.3607 - val_loss: 1.4689\n",
      "Epoch 2/6\n",
      "\u001b[1m1452/1452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 60ms/step - accuracy: 0.4539 - loss: 1.3374 - val_accuracy: 0.4478 - val_loss: 1.3230\n",
      "Epoch 3/6\n",
      "\u001b[1m1452/1452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 57ms/step - accuracy: 0.6085 - loss: 1.0028 - val_accuracy: 0.4895 - val_loss: 1.2894\n",
      "Epoch 4/6\n",
      "\u001b[1m1452/1452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 64ms/step - accuracy: 0.6779 - loss: 0.8224 - val_accuracy: 0.4911 - val_loss: 1.4126\n",
      "Epoch 5/6\n",
      "\u001b[1m1452/1452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 63ms/step - accuracy: 0.7126 - loss: 0.7162 - val_accuracy: 0.4923 - val_loss: 1.5058\n",
      "Epoch 6/6\n",
      "\u001b[1m1452/1452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 63ms/step - accuracy: 0.7441 - loss: 0.6323 - val_accuracy: 0.4910 - val_loss: 1.6974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f0ff8284ee0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 4\n",
    "model.fit(message_train, author_train, epochs=epochs, validation_data=(message_val, author_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.4895 - loss: 1.6900\n",
      "Test loss: 1.6957446336746216\n",
      "Test accuracy: 0.49417436122894287\n",
      "\u001b[1m1452/1452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 22ms/step - accuracy: 0.7885 - loss: 0.5306\n",
      "Recall loss: 0.5251414775848389\n",
      "Recall accuracy: 0.7910335063934326\n"
     ]
    }
   ],
   "source": [
    "# Test the model using the test data\n",
    "test_loss, test_accuracy = model.evaluate(message_test, author_test)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_accuracy)\n",
    "\n",
    "# Test recall\n",
    "recall_loss, recall_accuracy = model.evaluate(message_train, author_train)\n",
    "print('Recall loss:', recall_loss)\n",
    "print('Recall accuracy:', recall_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the stop words\n",
    "STOP_WORDS = urllib.request.urlopen(\"https://github.com/igorbrigadir/stopwords/blob/master/en/postgresql.txt\").read().decode(\"utf-8\").split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_message(message):\n",
    "    message = message.replace(\".\", \"\")\n",
    "    message = message.replace(\",\", \"\")\n",
    "    message = message.replace(\";\", \"\")\n",
    "    message = message.replace(\"!\", \"\")\n",
    "    message = message.replace(\"?\", \"\")\n",
    "    message = message.replace(\"(\", \"\")\n",
    "    message = message.replace(\")\", \"\")\n",
    "    message = message.replace(\"\\\\\", \"\")\n",
    "    message = message.replace(\"\\\"\", \"\")\n",
    "\n",
    "    # remove discord effects\n",
    "    message = message.replace(\"*\", \"\")\n",
    "    message = message.replace(\"_\", \"\")\n",
    "    message = message.replace(\"~\", \"\")\n",
    "    message = message.replace(\"`\", \"\")\n",
    "    message = message.replace(\">\", \"\")\n",
    "    message = message.replace(\"<\", \"\")\n",
    "    message = message.replace(\"||\", \"\")\n",
    "    message = message.replace(\"```\", \"\")\n",
    "    message = message.replace(\"~~\", \"\")\n",
    "    message = message.replace(\":\", \"\")\n",
    "    message = message.replace(\"#\", \"\")\n",
    "    message = message.replace(\"@\", \"\")\n",
    "\n",
    "\n",
    "    # remove stopwords\n",
    "    message = message.lower()\n",
    "    message = ' '.join([word for word in message.split() if word not in STOP_WORDS or word in USER_NAMES])\n",
    "\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "participating_users = { \"Shrimpy Raccoon\" : 0,\n",
    "                        \"Stella\" : 1,\n",
    "                        \"jeremy\" : 2,\n",
    "                        \"Nosmo\" : 3,\n",
    "                        \"matt_m_h\" : 4\n",
    "}\n",
    "users = list(participating_users.keys())\n",
    "\n",
    "def predict_string_author(test_message_raw):\n",
    "    # remove stopwords\n",
    "    test_message = clean_message(test_message_raw)\n",
    "    test_message_sequence = tokenizer.texts_to_sequences([test_message])\n",
    "    test_message_sequence = tf.keras.utils.pad_sequences(test_message_sequence, maxlen=max_len)\n",
    "    prediction = model.predict(test_message_sequence)\n",
    "    preds = []\n",
    "    for i, name in enumerate(users):\n",
    "        preds.append([name, prediction[0][i] * 100])\n",
    "    \n",
    "    return users[np.argmax(prediction)], prediction[0][np.argmax(prediction)] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
      "Message: Nyaa UwU I'm a femboy\n",
      "Predicted Author: Shrimpy Raccoon (99.02%)\n",
      "Actual Author: None\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Message: i'm going to become physically violent\n",
      "Predicted Author: jeremy (99.31%)\n",
      "Actual Author: None\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Message: kill sedimentary fuck metamorphic marry igneous\n",
      "Predicted Author: Stella (100.00%)\n",
      "Actual Author: None\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Message: kill me already\n",
      "Predicted Author: Shrimpy Raccoon (33.90%)\n",
      "Actual Author: None\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Message: face planted into the corner of a table\n",
      "Predicted Author: Nosmo (99.98%)\n",
      "Actual Author: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_message_raw = [\n",
    "    [\"Nyaa UwU I'm a femboy\", None],\n",
    "    [\"i'm going to become physically violent\", None],\n",
    "    [\"kill sedimentary fuck metamorphic marry igneous\", None],\n",
    "    [\"kill me already\", None],\n",
    "    [\"face planted into the corner of a table\", None]\n",
    "    ]\n",
    "\n",
    "for test_message, actual_author in test_message_raw:\n",
    "    username, prediction = predict_string_author(test_message)\n",
    "    print(f\"Message: {test_message}\\nPredicted Author: {username} ({prediction:.2f}%)\\nActual Author: {actual_author}\\n{'!!! CORRECT !!!' if actual_author == username else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as uber_boat_and_CH_OS_128_128_64_4_epoch_1_model.keras\n",
      "Weights saved as uber_boat_and_CH_OS_128_128_64_4_epoch_1_weights.weights.h5\n",
      "Tokenizer saved as uber_boat_and_CH_OS_128_128_64_4_epoch_1_tokenizer.json\n",
      "Model summary saved as uber_boat_and_CH_OS_128_128_64_4_epoch_1_model_summary.txt\n"
     ]
    }
   ],
   "source": [
    "model_name = \"uber_boat_and_CH_OS_128_128_64_4_epoch\"\n",
    "\n",
    "# Check if the model already exists if it already does add a number after it\n",
    "if os.path.exists(model_name + '_model.keras'):\n",
    "    model_name = model_name + '_1'\n",
    "    while os.path.exists(model_name + '_model.keras'):\n",
    "        model_name = model_name[:-1] + str(int(model_name[-1]) + 1)\n",
    "\n",
    "# Save the model\n",
    "model.save(model_name + '_model.keras')\n",
    "\n",
    "# tf.keras.saving.save_weights(model, 'chat_weights.keras')\n",
    "model.save_weights(model_name + '_weights.weights.h5')\n",
    "\n",
    "# model.save_weights('chat_weights.h5')\n",
    "tokenizer_json = tokenizer.to_json()\n",
    "with open(model_name + '_tokenizer.json', 'w') as json_file:\n",
    "    json_file.write(tokenizer_json)\n",
    "\n",
    "# Output the model summary\n",
    "with open(model_name + '_model_summary.txt', 'w') as f:\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "    f.write(f\"Epochs: {epochs}\\n\\n\")\n",
    "    f.write(f\"Testing Summary: \\n\")\n",
    "    f.write(f\"Test loss: {test_loss}\\n\")\n",
    "    f.write(f\"Test accuracy: {test_accuracy}\\n\")\n",
    "    f.write(f\"Recall loss: {recall_loss}\\n\")\n",
    "    f.write(f\"Recall accuracy: {recall_accuracy}\\n\")\n",
    "    f.write(f\"\\n\")\n",
    "    f.write(f\"Model files saved as: \\n\")\n",
    "    f.write(f\"Model saved as {model_name}_model.keras\\n\")\n",
    "    f.write(f\"Weights saved as {model_name}_weights.weights.h5\\n\")\n",
    "    f.write(f\"Tokenizer saved as {model_name}_tokenizer.json\\n\")\n",
    "\n",
    "print(f\"Model saved as {model_name}_model.keras\")\n",
    "print(f\"Weights saved as {model_name}_weights.weights.h5\")\n",
    "print(f\"Tokenizer saved as {model_name}_tokenizer.json\")\n",
    "print(f\"Model summary saved as {model_name}_model_summary.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Checking who owns what word\n",
    "# words = open(\"popular.txt\", \"r\").readlines()\n",
    "# wordlist_words = [word.strip() for word in words if word.strip() not in STOP_WORDS]\n",
    "# len(wordlist_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# owned_words = {}\n",
    "\n",
    "# f = open(\"owned_words.txt\", \"w\")\n",
    "\n",
    "# try:\n",
    "#     for word in wordlist_words:\n",
    "#         vals = predict_string_author(word)\n",
    "#         if vals[1] > 40:\n",
    "#             owned_words[word] = vals\n",
    "#             print(f\"{word},{vals[0]},{vals[1]}\", file=f)\n",
    "# except KeyboardInterrupt:\n",
    "#     f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
